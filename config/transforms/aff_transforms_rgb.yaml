train:
  - _target_: torchvision.transforms.Resize
    size: ${img_size}
  - _target_: affordance.dataloader.transforms.ColorTransform
    contrast: 0.05
    brightness: 0.05
    hue: 0.02
    prob: 1
  - _target_: affordance.dataloader.transforms.ScaleImageTensor  # Scale 0-255 to 0-1
  - _target_: torchvision.transforms.Normalize
    mean: [0.5,]
    std: [0.5,]
  - _target_: affordance.dataloader.transforms.AddGaussianNoise
    mean: [0.0]
    std: [0.01]
    clip: [-1, 1]
    
validation:
  - _target_: torchvision.transforms.Resize
    size: ${img_size}
  - _target_: affordance.dataloader.transforms.ScaleImageTensor
  - _target_: torchvision.transforms.Normalize
    mean: [0.5,]
    std: [0.5,]
  
masks:
  - _target_: torchvision.transforms.Resize
    size: ${img_size}
  # - _target_: affordance.dataloader.transforms.ScaleImageTensor  # Scale 0-255 to 0-1
  - _target_: affordance.dataloader.transforms.ThresholdMasks # Mask is between 0 and 255
    threshold: 50
  
masks_multitask:
  - _target_: torchvision.transforms.Resize
    size: ${img_size}